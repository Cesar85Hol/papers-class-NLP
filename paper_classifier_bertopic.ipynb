{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0RIUh43Hlki"
      },
      "source": [
        "# **ADSP - P8 PROJECT** - scientific papers classifier based on NLP\n",
        "---\n",
        "**CANDIDATES**\n",
        "\n",
        "GILLIO FRANCESCO\n",
        "\n",
        "SEMINARIO YRIGOYEN CESAR AUGUSTO\n",
        "\n",
        "**COURSE** Applied Data Science Project\n",
        "\n",
        "**University** Politecnico di Torino - Italy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djYmfMmHHlkj"
      },
      "source": [
        "## Project description\n",
        "\n",
        "**BertTopic** is used to create a semi-supervised model with labels available\n",
        "\n",
        "**Dataset** can be downloaded fro hugginface at the link: [Wiki Medical Terms](https://huggingface.co/datasets/gamino/wiki_medical_terms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBKZYzDvHlkj"
      },
      "source": [
        " ## <span style=\"font-family:Verdana; color:blue\">  0. TO DO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWTSOVEYHlkj"
      },
      "source": [
        "<span style=\"font-family:Verdana; color:blue\">\n",
        "\n",
        "- download similar dataset from hugging-face to start practicing\n",
        "- data cleaning\n",
        "- create embeddings\n",
        "- export embeddings\n",
        "- start with the model\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfO8yL9xHlkj"
      },
      "source": [
        "## 1. Exploring the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install bertopic\n",
        "!pip install datasets\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "gyIEojFpHqBW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vMZLEoH-Hlkk",
        "outputId": "e394e614-68b7-497f-add4-581c95d40f6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N° wiki terms: 1985\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import tqdm as notebook_tqdm\n",
        "\n",
        "dataset = load_dataset(\"dhiruHF/research_paper_multi_label_data_balanced\")\n",
        "terms_number= len(dataset['train'])\n",
        "print(f\"N° wiki terms: {terms_number}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_chapters(text):\n",
        "    chapters = text.split('###')[2]\n",
        "    labels = text.split('###')[3]\n",
        "    labels = labels.split(':')[1]\n",
        "    title=chapters.split('\\n')[2].split(':')[1]\n",
        "    abstract=chapters.split('\\n')[3:]\n",
        "    abstract[0]=abstract[0][9:]\n",
        "    delimiter=\"\\n\"\n",
        "    abstract=delimiter.join(abstract)\n",
        "    #labels=labels.split(',')\n",
        "    #labels=[label.strip() for label in labels]\n",
        "    item_dict={}\n",
        "    item_dict['title']=title\n",
        "    item_dict['abstract']=abstract\n",
        "    item_dict['labels']=labels\n",
        "    return item_dict\n",
        ""
      ],
      "metadata": {
        "id": "Ui9YVxQHKkEn"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item=get_chapters(dataset['train'][0]['text'])\n",
        "print(item['title'])"
      ],
      "metadata": {
        "id": "4bL-pWJ_NQbq",
        "outputId": "b76694b7-508b-4397-b248-49f263aed5e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Reconstructing Subject-Specific Effect Maps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0]['text'].split('###')[2]"
      ],
      "metadata": {
        "id": "KKpvGrCjIJoB",
        "outputId": "61b158ef-3bc5-4fdb-dd9f-8e70d271147d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"RESEARCH PAPER:\\n\\nTitle: Reconstructing Subject-Specific Effect Maps\\nAbstract:   Predictive models allow subject-specific inference when analyzing disease\\nrelated alterations in neuroimaging data. Given a subject's data, inference can\\nbe made at two levels: global, i.e. identifiying condition presence for the\\nsubject, and local, i.e. detecting condition effect on each individual\\nmeasurement extracted from the subject's data. While global inference is widely\\nused, local inference, which can be used to form subject-specific effect maps,\\nis rarely used because existing models often yield noisy detections composed of\\ndispersed isolated islands. In this article, we propose a reconstruction\\nmethod, named RSM, to improve subject-specific detections of predictive\\nmodeling approaches and in particular, binary classifiers. RSM specifically\\naims to reduce noise due to sampling error associated with using a finite\\nsample of examples to train classifiers. The proposed method is a wrapper-type\\nalgorithm that can be used with different binary classifiers in a diagnostic\\nmanner, i.e. without information on condition presence. Reconstruction is posed\\nas a Maximum-A-Posteriori problem with a prior model whose parameters are\\nestimated from training data in a classifier-specific fashion. Experimental\\nevaluation is performed on synthetically generated data and data from the\\nAlzheimer's Disease Neuroimaging Initiative (ADNI) database. Results on\\nsynthetic data demonstrate that using RSM yields higher detection accuracy\\ncompared to using models directly or with bootstrap averaging. Analyses on the\\nADNI dataset show that RSM can also improve correlation between\\nsubject-specific detections in cortical thickness data and non-imaging markers\\nof Alzheimer's Disease (AD), such as the Mini Mental State Examination Score\\nand Cerebrospinal Fluid amyloid-$\\\\beta$ levels. Further reliability studies on\\nthe longitudinal ADNI dataset show improvement on detection reliability when\\nRSM is used.\\n\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict=[get_chapters(item) for item in dataset['train']['text']]"
      ],
      "metadata": {
        "id": "Wjy0lpybPB4u"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"title:\\n {data_dict[34]['title']}\")\n",
        "print(f\"abstract:\\n {data_dict[34]['abstract']}\")\n",
        "print(f\"labels:\\n {data_dict[34]['labels']}\")"
      ],
      "metadata": {
        "id": "fH2a-CH5Plu4",
        "outputId": "d5ac7496-c282-4eca-a590-53dc68c9bf9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "title:\n",
            "  Deep Neural Network Optimized to Resistive Memory with Nonlinear Current-Voltage Characteristics\n",
            "abstract:\n",
            "    Artificial Neural Network computation relies on intensive vector-matrix\n",
            "multiplications. Recently, the emerging nonvolatile memory (NVM) crossbar array\n",
            "showed a feasibility of implementing such operations with high energy\n",
            "efficiency, thus there are many works on efficiently utilizing emerging NVM\n",
            "crossbar array as analog vector-matrix multiplier. However, its nonlinear I-V\n",
            "characteristics restrain critical design parameters, such as the read voltage\n",
            "and weight range, resulting in substantial accuracy loss. In this paper,\n",
            "instead of optimizing hardware parameters to a given neural network, we propose\n",
            "a methodology of reconstructing a neural network itself optimized to resistive\n",
            "memory crossbar arrays. To verify the validity of the proposed method, we\n",
            "simulated various neural network with MNIST and CIFAR-10 dataset using two\n",
            "different specific Resistive Random Access Memory (RRAM) model. Simulation\n",
            "results show that our proposed neural network produces significantly higher\n",
            "inference accuracies than conventional neural network when the synapse devices\n",
            "have nonlinear I-V characteristics.\n",
            "\n",
            "\n",
            "\n",
            "labels:\n",
            "  ['Computer Science']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prX-RJquHlkk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQKdoD3cHlkk"
      },
      "source": [
        "## 2. Preparing the dataset for BERTopic architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTQquHzdHlkl"
      },
      "outputs": [],
      "source": [
        "# functions preparing the dataset for BERTopic architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f4lXW1-Hlkl"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ET8POfX_Hlkl",
        "outputId": "ce1941da-f267-4e47-bc25-9a7171f9472d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initial size: (6861, 3)\n",
            "new size of items after removing duplicates: (6762, 3)\n",
            "new size of items after removing na or empty sign & symptomps: (2255, 3)\n"
          ]
        }
      ],
      "source": [
        "#CLEANING DUPLICATES & NAN SECTION VALUES\n",
        "\n",
        "print(f\"initial size: {md_terms_df.shape}\")\n",
        "# removing duplicates\n",
        "md_terms_ss_df=md_terms_df.drop_duplicates(subset=['medical_term'], keep='first')\n",
        "print(f\"new size of items after removing duplicates: {md_terms_ss_df.shape}\")\n",
        "\n",
        "#removing nan or empty sign & symptomps terms\n",
        "md_terms_ss_df=md_terms_ss_df[md_terms_ss_df['signs_and_symptoms'].astype(bool)]\n",
        "# md_terms_df=md_terms_df.dropna( )\n",
        "print(f\"new size of items after removing na or empty sign & symptomps: {md_terms_ss_df.shape}\")\n",
        "md_terms_ss_df.to_excel('diseases_correct.xlsx')\n",
        "# md_terms_ss_df=add_groundtruth(\"ICD-11_class.xlsx\",md_terms_ss_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FPj51ziHlkl"
      },
      "outputs": [],
      "source": [
        "''' wordcloud example\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text = md_terms_ss_df['description'][52]\n",
        "\n",
        "x, y = np.ogrid[:300, :300]\n",
        "\n",
        "mask = (x - 150) ** 2 + (y - 150) ** 2 > 130 ** 2\n",
        "mask = 255 * mask.astype(int)\n",
        "\n",
        "\n",
        "wc = WordCloud(background_color=\"white\", repeat=True, mask=mask)\n",
        "wc.generate(text)\n",
        "\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(wc, interpolation=\"bilinear\")\n",
        "plt.show()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-vAdizRHlkl",
        "outputId": "a5163372-0a1b-4164-8bdc-9bb9ecbd2e31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dictionary terms (useful to be classificated)\n",
            "{\n",
            "    \"idx\": 140,\n",
            "    \"md_term\": \"Type 1 diabetes\",\n",
            "    \"md_description\": \"Type 1 diabetes (T1D), formerly known as juvenile diabetes, is an autoimmune disease that originates when cells that make insulin (beta cells) are destroyed by the immune system. Insulin is a hormone required for the cells to use blood sugar for energy and it helps regulate glucose levels in the bloodstream. Before treatment this results in high blood sugar levels in the body. The common symptoms of this elevated blood sugar are frequent urination, increased thirst, increased hunger, weight loss, and other serious complications. Additional symptoms may include blurry vision, tiredness, and slow wound healing. Symptoms typically develop over a short period of time, often a matter of weeks.The cause of type 1 diabetes is unknown, but it is believed to involve a combination of genetic and environmental factors. The underlying mechanism involves an autoimmune destruction of the insulin-producing beta cells in the pancreas. Diabetes is diagnosed by testing the level of sugar or glycated hemoglobin (HbA1C) in the blood. Type 1 diabetes can be distinguished from type 2 by testing for the presence of autoantibodies.There is no known way to prevent type 1 diabetes. Treatment with insulin is required for survival. Insulin therapy is usually given by injection just under the skin but can also be delivered by an insulin pump. A diabetic diet and exercise are important parts of management. If left untreated, diabetes can cause many complications. Complications of relatively rapid onset include diabetic ketoacidosis and nonketotic hyperosmolar coma. Long-term complications include heart disease, stroke, kidney failure, foot ulcers and damage to the eyes. Furthermore, since insulin lowers blood sugar levels, complications may arise from low blood sugar if more insulin is taken than necessary.Type 1 diabetes makes up an estimated 5\\u201310% of all diabetes cases. The number of people affected globally is unknown, although it is estimated that about 80,000 children develop the disease each year. Within the United States the number of people affected is estimated at one to three million. Rates of disease vary widely, with approximately one new case per 100,000 per year in East Asia and Latin America and around 30 new cases per 100,000 per year in Scandinavia and Kuwait. It typically begins in children and young adults.\",\n",
            "    \"Sign and Symptoms\": \"Type 1 diabetes begins suddenly, typically in childhood or adolescence. The major sign of type 1 diabetes is very high blood sugar, which typically manifests in children as a few days to weeks of polyuria (increased urination), polydipsia (increased thirst), and weight loss. Children may also experience increased appetite, blurred vision, bedwetting, recurrent skin infections, candidiasis of the perineum, irritability, and performance issues at school. Adults with type 1 diabetes tend to have more varied symptoms that come on over months rather than days to weeks.Prolonged lack of insulin can also result in diabetic ketoacidosis, characterized by persistent fatigue, dry or flushed skin, abdominal pain, nausea or vomiting, confusion, trouble breathing, and a fruity breath odor. Blood and urine tests reveal unusually high glucose and ketones in the blood and urine. Untreated ketoacidosis can rapidly progress to loss of consciousness, coma, and death. The percentage of children whose type 1 diabetes begins with an episode of diabetic ketoacidosis varies widely by geography, as low as 15% in parts of Europe and North America, and as high as 80% in the developing world.. \"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "#PREPARING DATASET FOT BERTOPIC\n",
        "import json\n",
        "data_dict=[]\n",
        "for idx in md_terms_ss_df.index:\n",
        "    tmp_dict={}\n",
        "    tmp_dict['idx']=idx\n",
        "    tmp_dict['md_term']=md_terms_ss_df['medical_term'][idx]\n",
        "    tmp_dict['md_description']=md_terms_ss_df['description'][idx]\n",
        "    tmp_dict['Sign and Symptoms']=create_paragraph(md_terms_ss_df['signs_and_symptoms'][idx])\n",
        "    data_dict.append(tmp_dict)\n",
        "\n",
        "print(\"dictionary terms (useful to be classificated)\")\n",
        "print(json.dumps(data_dict[50],indent=4))\n",
        "#print(wiki_description[md_terms_ss_df['medical_term'][50]])\n",
        "# s2=create_paragraph(possible_signs_syntomps[1])\n",
        "# print(possible_signs_syntomps[1])\n",
        "# print(f\"as paragraph: {s2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHKx3zfBHlkl",
        "outputId": "46b0cb23-eaf9-4741-fbf2-44385334fa71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2255\n"
          ]
        }
      ],
      "source": [
        "# disease_terms=[]\n",
        "# disease_descriptions=[]\n",
        "# disease_sign_syntomps=[]\n",
        "# i=0\n",
        "# for syntomp in signs_symptoms:\n",
        "#     if(syntomp!=[]):\n",
        "#         disease_terms.append(wiki_terms[i])\n",
        "#         disease_descriptions.append(wiki_description[i].split('\\n')[0] )\n",
        "#         disease_sign_syntomps.append(syntomp)\n",
        "#         i+=1\n",
        "# data_dict_2={'medical_term':disease_terms,'description':disease_descriptions,'signs_and_symptoms':disease_sign_syntomps}\n",
        "# diseases_df=pd.DataFrame(data_dict_2)\n",
        "# print(diseases_df.head(2))\n",
        "# print(f\"{len(disease_sign_syntomps)} diseases found in the dataset\")\n",
        "# diseases_df.to_excel('diseases.xlsx')\n",
        "# syntomps_as_paragrapgh=[create_paragraph(s) for s in disease_sign_syntomps]\n",
        "symtomps_as_paragraph=[]\n",
        "symtomps_as_paragraph=[create_paragraph(s) for s in md_terms_ss_df['signs_and_symptoms']]\n",
        "print(len(symtomps_as_paragraph))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6em_DIoHlkl"
      },
      "source": [
        "## 3. Setting up base BERTopic model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efYp_hCcHlkl"
      },
      "source": [
        "### 3.1 Precalculate embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JDCthVtHlkl"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Pre-calculate embeddings\n",
        "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pc1-UwKHlkl",
        "outputId": "4e4cf959-13ad-436c-c343-be10cc5b6ae1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 71/71 [05:55<00:00,  5.01s/it]\n"
          ]
        }
      ],
      "source": [
        "embeddings = embedding_model.encode(symtomps_as_paragraph, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCkbD9dfHlkl"
      },
      "source": [
        "### 3.2 Setting up bertopic blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqsEotSgHlkl"
      },
      "outputs": [],
      "source": [
        "#!pip install 'umap-learn==0.3.10'\n",
        "from umap import UMAP\n",
        "umap_model = UMAP(n_neighbors=20, n_components=5, min_dist=0.0, metric='cosine', random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iabxN4t8Hlkm"
      },
      "outputs": [],
      "source": [
        "from hdbscan import HDBSCAN\n",
        "hdbscan_model = HDBSCAN(min_cluster_size=20, metric='euclidean', cluster_selection_method='eom', prediction_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXgJkkz9Hlkm"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction import text\n",
        "additional_stopwords=['Signs','signs','Sign', 'sign', 'Symptoms','symptoms','Symptom','symptom','include','affected','people','features','patients','disease','present','common','usually'] #'syndrome', disease, patient, patients\n",
        "stop_words_mod=list(text.ENGLISH_STOP_WORDS)+additional_stopwords\n",
        "vectorizer_model = CountVectorizer(stop_words=stop_words_mod, min_df=1, ngram_range=(1, 2))\n",
        "# vectorizer_model = CountVectorizer(stop_words=\"english\", min_df=2, ngram_range=(1, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9peFXQEHlkm"
      },
      "source": [
        "### 3.3 DEFINING representation models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqHDZQRMHlkm"
      },
      "outputs": [],
      "source": [
        "#!pip install typing-extensions --upgrade\n",
        "\n",
        "import openai\n",
        "import bertopic\n",
        "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, OpenAI, PartOfSpeech\n",
        "#from spacy import parts_of_speech\n",
        "# KeyBERT\n",
        "keybert_model = KeyBERTInspired()\n",
        "\n",
        "# Part-of-Speech\n",
        "#pos_model = PartOfSpeech(\"en_core_web_sm\")\n",
        "# MMR\n",
        "mmr_model = MaximalMarginalRelevance(diversity=0.3)\n",
        "\n",
        "# GPT-3.5\n",
        "prompt = \"\"\"\n",
        "I have a topic that contains the following documents:\n",
        "[DOCUMENTS]\n",
        "The topic is described by the following keywords: [KEYWORDS]\n",
        "\n",
        "Based on the information above, extract a short but highly descriptive topic label of at most 5 words. Make sure it is in the following format:\n",
        "topic: <topic label>\n",
        "\"\"\"\n",
        "client = openai.OpenAI(api_key=\"sk-...\")\n",
        "#openai_model = OpenAI(client, model=\"gpt-3.5-turbo\", exponential_backoff=True, chat=True, prompt=prompt)\n",
        "\n",
        "# All representation models\n",
        "representation_model = {\n",
        "    \"KeyBERT\": keybert_model,\n",
        "    # \"OpenAI\": openai_model,  # Uncomment if you will use OpenAI\n",
        "    \"MMR\": mmr_model,\n",
        "    #\"POS\": pos_model\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kq_f5FyHlkm"
      },
      "source": [
        "## 4. Model exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdBiObB_Hlkm"
      },
      "source": [
        "### Tests:\n",
        "HDBSCAN - choose reasonable number of topics\n",
        "\n",
        "\n",
        "Vectorizer tests\n",
        "- mindf=1 : changes just group 12: war--- to veteran.sle, war, gulf. # of topics are the same. SLe is the most representative doc, it's autoimmune disease\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuJz8FxRHlkm",
        "outputId": "8c476aef-6168-4413-c502-976f9a19b673"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-18 22:59:19,437 - BERTopic - Reduced dimensionality\n",
            "2024-02-18 22:59:19,504 - BERTopic - Clustered reduced embeddings\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "size (1, 3) analyzed\n"
          ]
        }
      ],
      "source": [
        "from bertopic import BERTopic\n",
        "from sklearn.cluster import KMeans\n",
        "#put here the block to study in order to understand behaviors\n",
        "# list_to_check=range(20,160,10)\n",
        "list_to_check=[(1,3)]\n",
        "\n",
        "params=[]\n",
        "# list_to_check=range(140,160,10)\n",
        "for size in list_to_check:#reversed(list_to_check):\n",
        "  # hdbscan_model = HDBSCAN(min_cluster_size=size, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
        "  vectorizer_model = CountVectorizer(stop_words=stop_words_mod, min_df=1, ngram_range=size)\n",
        "  # hdbscan_model= KMeans(n_clusters=size)\n",
        "  topic_model = BERTopic(\n",
        "\n",
        "  # Pipeline models\n",
        "  embedding_model=embedding_model,\n",
        "  umap_model=umap_model,\n",
        "  hdbscan_model=hdbscan_model,\n",
        "  vectorizer_model=vectorizer_model,\n",
        "  representation_model=representation_model,\n",
        "\n",
        "  # Hyperparameters\n",
        "  top_n_words=10,\n",
        "  verbose=True\n",
        ")\n",
        "  topics, probs = topic_model.fit_transform(symtomps_as_paragraph, embeddings)\n",
        "  print(f\"size {size} analyzed\")\n",
        "  a=topic_model.get_topic_freq()\n",
        "  # a['index_old']=a.index\n",
        "  b=topic_model.get_topic_info()['Name']\n",
        "  a.reset_index(inplace=True)\n",
        "  b.reset_index(drop=True)\n",
        "  a=pd.concat([a,b],axis=1)\n",
        "  params.append(a)\n",
        "  topic_model.get_topic_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYk8jOGPHlkm"
      },
      "outputs": [],
      "source": [
        "topic_model.get_topic_info()\n",
        "# params[13].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbNWJCvpHlkm"
      },
      "outputs": [],
      "source": [
        "topic_model.get_representative_docs(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZvFosnhHlkm"
      },
      "source": [
        "### saving model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsQSm_3YHlkm"
      },
      "outputs": [],
      "source": [
        "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "topic_model.save(\"./model_dir/hdbscan\", serialization=\"safetensors\", save_ctfidf=True, save_embedding_model=embedding_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSlMxq6bHlkm"
      },
      "source": [
        "### Accuracy Calculation\n",
        "- find metrics - remember ICD11 per clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKlR4BiGHlkm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCb5LSiTHlkm"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdlXYzWkHlkm"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezHKWWcSHlkm"
      },
      "source": [
        "#### OPEC evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uiaEM-IHlkm"
      },
      "outputs": [],
      "source": [
        "#creating dataset ready for opec\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaaZDEplHlkm"
      },
      "source": [
        "### Creating plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLMuQegyHlkm"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MKL3_u_Hlkn"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ug9VE8HFHlkn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q3M_YYyHlkn"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nphXENluHlkn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9k1RynXHlkn"
      },
      "source": [
        "### Model visualization: topics and documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7DO2Np0Hlkn"
      },
      "outputs": [],
      "source": [
        "topic_model.visualize_topics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XPKVQ1JHlkn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf0Lhv2jHlkn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TInKTgjGHlkn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCnTQYrmHlkn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcommjtHHlkn"
      },
      "outputs": [],
      "source": [
        "topic_model.visualize_hierarchy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jt9IMmC3Hlkn"
      },
      "outputs": [],
      "source": [
        "# Documents\n",
        "from umap import UMAP\n",
        "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)\n",
        "# Visualize the documents in 2-dimensional space and show the titles on hover instead of the abstracts\n",
        "# NOTE: You can hide the hover with `hide_document_hover=True` which is especially helpful if you have a large dataset\n",
        "labels=md_terms_ss_df['medical_term'].to_list()\n",
        "topic_model.visualize_documents(labels, reduced_embeddings=reduced_embeddings)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DLNPenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}